{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading the image using OpenCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "image = cv2.imread('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('input_image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the image into grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "lanelines_image = np.copy(image)\n",
    "gray_conversion = cv2.cvtColor(lanelines_image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('imput_image', gray_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('input_image', blur_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny edge detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conversion = cv2.Canny(blur_conversion, 50,155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('input_image', canny_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "    gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0) \n",
    "    canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "    return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "    Image_height  = image.shape[0]\n",
    "    polygons = np.array([[(200, Image_height), (1100, Image_height), (550, 250)]])\n",
    "    image_mask = np.zeros_like(image)\n",
    "    cv2. fillPoly(image_mask, polygons, 255)\n",
    "    return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "lanelines_image = np.copy(image)\n",
    "canny_conversion = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', reg_of_interest(canny_conversion))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying bitwise_and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "    gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0) \n",
    "    canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "    return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "    image_height  = image.shape[0]\n",
    "    polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "    image_mask = np.zeros_like(image)\n",
    "    cv2. fillPoly(image_mask, polygons, 255)\n",
    "    masking_image = cv2.bitwise_and(image, image_mask)\n",
    "    return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "lanelines_image = np.copy(image)\n",
    "canny_conversion = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_conversion)\n",
    "cv2.imshow('result', cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "    lines_image = np.zeros_like(image)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            X1, Y1, X2, Y2 = line.reshape(4)\n",
    "            cv2.line(lines_image, (X1, Y1), (X2, Y2),(255,0,0), 10)\n",
    "    return lines_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "lanelines_image = np.copy(image)\n",
    "canny_conv = canny_edge(lanelines_image)\n",
    "cropped_image = reg_of_interest(canny_conv)\n",
    "lane_lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)\n",
    "linelines_image = show_lines(lanelines_image, lane_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', linelines_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the detected road markings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting road markings in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
